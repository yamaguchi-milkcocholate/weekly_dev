import json
from typing import Any, Dict, Optional

from dotenv import load_dotenv
from langchain_core.messages import HumanMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import END, StateGraph

import sns_ai_automation_agency.agent.restaurant.schema as schema
import sns_ai_automation_agency.utils as utils


def survey_restaurant_information(station_name: str, num_iterations: int, thread_id: Optional[str] = None) -> dict:
    load_dotenv()

    if thread_id:
        cache = utils.CachePathManager(app_name=thread_id)
        cache_file = cache.file(f"restaurant_survey_{station_name}.json")

        if cache_file.exists():
            with open(cache_file, "r", encoding="utf-8") as f:
                return json.load(f)
    else:
        cache, cache_file = None, None

    # LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ§‹ç¯‰
    workflow = StateGraph(schema.RestaurantSurveyState)

    # ãƒãƒ¼ãƒ‰ã®è¿½åŠ 
    workflow.add_node("restaurant_survey_node", restaurant_survey_node)
    workflow.add_node("analysis_and_planning_node", analysis_and_planning_node)

    # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®šç¾©
    workflow.set_entry_point("restaurant_survey_node")

    # èª¿æŸ»å®Ÿè¡Œå¾Œã¯å¿…ãšåˆ†æã¸
    workflow.add_conditional_edges(
        "restaurant_survey_node",
        should_continue_adaptive_survey,
        {"analysis_and_planning_node": "analysis_and_planning_node", END: END},
    )

    # åˆ†æå¾Œã¯ç¶™ç¶šåˆ¤å®šã«åŸºã¥ã„ã¦æ¬¡å›èª¿æŸ»ã¾ãŸã¯çµ‚äº†
    workflow.add_conditional_edges(
        "analysis_and_planning_node",
        should_continue_adaptive_survey,
        {"restaurant_survey_node": "restaurant_survey_node", END: END},
    )

    # ãƒ¡ãƒ¢ãƒªè¨­å®š
    memory = MemorySaver()

    # ã‚°ãƒ©ãƒ•ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
    agent = workflow.compile(checkpointer=memory)

    initial_state = {
        "station_name": station_name,
        "max_iterations": num_iterations,
        "survey_iteration": 0,
        "messages": [HumanMessage(content=f"{station_name}ã®é©å¿œçš„é£²é£Ÿåº—èª¿æŸ»ã‚’é–‹å§‹ã—ã¦ãã ã•ã„")],
    }
    config = {"configurable": {"thread_id": f"restaurant_survey_{station_name}.json"}}

    result: schema.RestaurantSurveyState = agent.invoke(initial_state, config)
    result_dict = utils.to_serializable(result)

    if cache:
        with open(cache_file, "w", encoding="utf-8") as f:
            json.dump(result_dict, f, ensure_ascii=False, indent=4)

    return result_dict


@tool
def search_food_areas_with_web_api(
    station_name: str, search_query: str, exclusion_criteria: str = ""
) -> schema.FoodAreaSearchResponse:
    """Web APIæ©Ÿèƒ½ä»˜ããƒ¢ãƒ‡ãƒ«ã§é£²é£Ÿåº—ã‚¨ãƒªã‚¢æƒ…å ±ã‚’æ¤œç´¢ï¼ˆSNSå‘ã‘ç‰¹åŒ–ã€ã‚¨ãƒªã‚¢å˜ä½ã®æ§‹é€ åŒ–å‡ºåŠ›ï¼‰"""
    # gpt-5-search-api ã‚’ä½¿ç”¨ã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œç´¢ï¼ˆã‚¨ãƒªã‚¢å˜ä½ã®æ§‹é€ åŒ–å‡ºåŠ›ï¼‰
    search_llm = ChatOpenAI(model="gpt-5-search-api", temperature=0.1)
    structured_llm = search_llm.with_structured_output(schema.FoodAreaSearchResponse)

    search_prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """
ã‚ãªãŸã¯SNSå‘ã‘é£²é£Ÿåº—ã‚¨ãƒªã‚¢å°‚é–€ãƒªã‚µãƒ¼ãƒãƒ£ãƒ¼ã§ã™ã€‚
Webæ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ã£ã¦ã€æŒ‡å®šã•ã‚ŒãŸé§…å‘¨è¾ºã®é£²é£Ÿåº—ã‚¨ãƒªã‚¢æƒ…å ±ã‚’äº‹å®Ÿãƒ™ãƒ¼ã‚¹ã§èª¿æŸ»ã—ã€
**ã‚¨ãƒªã‚¢å˜ä½ã§ã¾ã¨ã‚ãŸæ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹**ã¨ã—ã¦è¿”ã—ã¦ãã ã•ã„ã€‚


ğŸ¯ SNSç‰¹åŒ–ã‚¨ãƒªã‚¢å˜ä½èª¿æŸ»ãƒã‚¤ãƒ³ãƒˆï¼š
1. å•†åº—è¡—ãƒ»é£Ÿã¹æ­©ãã‚¨ãƒªã‚¢ãƒ»ã‚°ãƒ«ãƒ¡è¡—ã®ç‰¹å®š
2. ã‚¨ãƒªã‚¢å†…ã®ä»£è¡¨çš„ãªé£²é£Ÿåº—ã®æƒ…å ±ï¼ˆåº—èˆ—åãƒ»æ¥­æ…‹ãƒ»ä¾¡æ ¼å¸¯ãƒ»å–¶æ¥­æ™‚é–“ï¼‰
3. ã‚¨ãƒªã‚¢å…¨ä½“ã®ç‰¹å¾´ãƒ»é›°å›²æ°—ãƒ»ã‚³ãƒ³ã‚»ãƒ—ãƒˆ
4. é§…ã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹æƒ…å ±ï¼ˆå¾’æ­©æ™‚é–“ç¯„å›²ï¼‰
5. ã‚¨ãƒªã‚¢å…¨ä½“ã®SNSã‚¢ãƒ”ãƒ¼ãƒ«ãƒã‚¤ãƒ³ãƒˆï¼ˆçµ±ä¸€æ„Ÿã®ã‚ã‚‹å†…è£…ã€è¡—ä¸¦ã¿ã€ãƒ•ã‚©ãƒˆã‚¹ãƒãƒƒãƒˆã€è©±é¡Œã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãªã©ï¼‰
6. ã‚¨ãƒªã‚¢ã®è©±é¡Œæ€§ãƒ»äººæ°—åº¦ï¼ˆãƒ¡ãƒ‡ã‚£ã‚¢éœ²å‡ºã€è¦³å…‰åœ°åŒ–ã€åœ°å…ƒå¯†ç€åº¦ãªã©ï¼‰
7. ã‚¨ãƒªã‚¢å…¨ä½“ã§ã®SNSæŠ•ç¨¿ä¾¡å€¤ï¼ˆãƒ†ãƒ¼ãƒæ€§ã€å›éŠæ€§ã€æ’®å½±ã‚¹ãƒãƒƒãƒˆã®è±Šå¯Œã•ï¼‰
8. ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºï¼ˆGoogleå£ã‚³ãƒŸã€SNSæŠ•ç¨¿ã€è¦³å…‰ã‚µã‚¤ãƒˆã€ã‚°ãƒ«ãƒ¡ã‚µã‚¤ãƒˆã€åœ°åŸŸæƒ…å ±ãªã©ï¼‰

ğŸ“‹ ã‚¨ãƒªã‚¢å˜ä½ãƒ‡ãƒ¼ã‚¿è¦ä»¶ï¼š
- å„ã‚¨ãƒªã‚¢ã«3-8åº—èˆ—ç¨‹åº¦ã‚’å«ã‚ã‚‹
- ã‚¨ãƒªã‚¢ã®å¾’æ­©æ™‚é–“ç¯„å›²ã‚’æ˜ç¢ºã«
- ã‚¨ãƒªã‚¢ã”ã¨ã®SNSç‰¹åŒ–è¦ç´ ã‚’å…·ä½“çš„ã«ï¼ˆä¾‹ï¼šã€Œãƒ¬ãƒˆãƒ­å•†åº—è¡—ã®çµ±ä¸€çœ‹æ¿ã€ã€Œã‚«ãƒ•ã‚§è¡—ã®ç·‘è±Šã‹ãªé›°å›²æ°—ã€ï¼‰
- é™¤å¤–æ¡ä»¶ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯å³æ ¼ã«é©ç”¨
- ã‚¨ãƒªã‚¢æƒ…å ±ã®ä¿¡é ¼æ€§ã‚’è©•ä¾¡

**é‡è¦**: å€‹åˆ¥åº—èˆ—ã§ã¯ãªãã€é£²é£Ÿåº—ãŒé›†ç©ã™ã‚‹ã€Œã‚¨ãƒªã‚¢ã€ã‚’ä¸­å¿ƒã«èª¿æŸ»ãƒ»æ•´ç†ã—ã¦ãã ã•ã„ã€‚
            """,
            ),
            (
                "user",
                """
é§…å: {station_name}
èª¿æŸ»å†…å®¹: {search_query}
é™¤å¤–æ¡ä»¶: {exclusion_criteria}

ä¸Šè¨˜ã®æ¡ä»¶ã§SNSå‘ã‘é£²é£Ÿåº—ã‚¨ãƒªã‚¢èª¿æŸ»ã‚’å®Ÿè¡Œã—ã€**ã‚¨ãƒªã‚¢å˜ä½ã§ã¾ã¨ã‚ãŸ**æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã§è¿”ã—ã¦ãã ã•ã„ã€‚
ç‰¹ã«ä»¥ä¸‹ã‚’é‡è¦–ï¼š
- ã‚¨ãƒªã‚¢ã”ã¨ã®é£²é£Ÿåº—é›†ç©çŠ¶æ³
- ã‚¨ãƒªã‚¢å…¨ä½“ã®ã‚¤ãƒ³ã‚¹ã‚¿æ˜ ãˆã™ã‚‹ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è¦ç´ 
- ã‚¨ãƒªã‚¢ã®çµ±ä¸€æ„Ÿãƒ»ãƒ†ãƒ¼ãƒæ€§ãƒ»è©±é¡Œæ€§
- å„ã‚¨ãƒªã‚¢å†…ã®ä»£è¡¨åº—èˆ—æƒ…å ±
- ãƒ‡ãƒ¼ã‚¿ã®ä¿¡é ¼æ€§ã¨æ­£ç¢ºæ€§
            """,
            ),
        ]
    )

    chain = search_prompt | structured_llm
    response: schema.FoodAreaSearchResponse = chain.invoke(
        {
            "station_name": station_name,
            "search_query": search_query,
            "exclusion_criteria": exclusion_criteria or "ãªã—",
        }
    )

    print("  ğŸ” é£²é£Ÿåº—ã‚¨ãƒªã‚¢æ¤œç´¢å®Œäº†: ")
    print(f"    - ç™ºè¦‹ã‚¨ãƒªã‚¢æ•°: {response.total_areas_found}")
    print(f"    - æ¤œç´¢ã‚«ãƒãƒ¬ãƒƒã‚¸: {response.search_area_coverage.strip()}")
    print(f"    - é™¤å¤–æ¡ä»¶é©ç”¨: {'ã¯ã„' if response.exclusion_applied else 'ã„ã„ãˆ'}")
    print(f"    - ãƒ‡ãƒ¼ã‚¿ä¿¡é ¼æ€§: {response.data_reliability}")

    return response


# Node 1: SNSç‰¹åŒ–é£²é£Ÿåº—èª¿æŸ»å®Ÿè¡Œãƒãƒ¼ãƒ‰ï¼ˆLangGraph reducerå¯¾å¿œãƒ»ã‚¨ãƒªã‚¢å˜ä½ãƒ»LLMãƒ™ãƒ¼ã‚¹ã®ã‚µãƒãƒªãƒ¼ç”Ÿæˆï¼‰
def restaurant_survey_node(state: schema.RestaurantSurveyState) -> schema.RestaurantSurveyState:
    """ç¾åœ¨ã®èª¿æŸ»æˆ¦ç•¥ã«åŸºã¥ã„ã¦é£²é£Ÿåº—ã‚¨ãƒªã‚¢æƒ…å ±ã‚’åé›†ï¼ˆSNSç‰¹åŒ–ãƒ»ã‚¨ãƒªã‚¢å˜ä½ï¼‰"""
    print(f"ğŸ” SNSç‰¹åŒ–é£²é£Ÿåº—ã‚¨ãƒªã‚¢èª¿æŸ»å®Ÿè¡Œãƒãƒ¼ãƒ‰é–‹å§‹ (ç¬¬{state['survey_iteration'] + 1}å›)")

    # æ¬¡å›èª¿æŸ»ã®æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—
    search_params = _get_search_params(state)
    # Web APIæ¤œç´¢å®Ÿè¡Œï¼ˆã‚¨ãƒªã‚¢å˜ä½ã®æ§‹é€ åŒ–å‡ºåŠ›ï¼‰
    search_response = search_food_areas_with_web_api.invoke(
        {
            "station_name": search_params["station_name"],
            "search_query": search_params["search_query"],
            "exclusion_criteria": search_params["exclusion_criteria"],
        }
    )

    # LLMã‚’ä½¿ç”¨ã—ã¦SurveySummaryã‚’ç”Ÿæˆ
    survey_summary = _generate_survey_summary_with_llm(
        state=state, search_response=search_response, search_params=search_params
    )

    # LangGraph reducerå¯¾å¿œï¼šæ–°ã—ã„è¦ç´ ã‚’returnã§è¿”ã™
    result = {
        "current_process": "restaurant_survey_node",
        "survey_iteration": state["survey_iteration"] + 1,
        "discovered_areas": survey_summary.new_areas_found,  # è‡ªå‹•çš„ã«æ—¢å­˜ãƒªã‚¹ãƒˆã«çµåˆã•ã‚Œã‚‹
        "survey_history": [survey_summary],  # è‡ªå‹•çš„ã«æ—¢å­˜ãƒªã‚¹ãƒˆã«çµåˆã•ã‚Œã‚‹
    }

    print(f"  ğŸ“š èª¿æŸ»å±¥æ­´: {len(state['survey_history']) + 1}å›åˆ†è“„ç©")

    return result


def _generate_survey_summary_with_llm(
    state: schema.RestaurantSurveyState, search_response: schema.FoodAreaSearchResponse, search_params: Dict[str, Any]
) -> schema.SurveySummary:
    """LLMã‚’ä½¿ç”¨ã—ã¦SurveySummaryã‚’ç”Ÿæˆã™ã‚‹ï¼ˆwith_structured_outputä½¿ç”¨ï¼‰"""

    search_result = (
        json.dumps(search_response.model_dump(), indent=2, ensure_ascii=False).replace("{", "{{").replace("}", "}}")
    )
    survey_history = "\n,".join(
        [
            json.dumps(sh.model_dump(), indent=2, ensure_ascii=False).replace("{", "{{").replace("}", "}}")
            for sh in state["survey_history"]
        ]
    )

    # æ§‹é€ åŒ–å‡ºåŠ›ã‚’ä½¿ç”¨ã™ã‚‹LLM
    summary_llm = ChatOpenAI(model="gpt-5-mini", temperature=0)
    structured_llm = summary_llm.with_structured_output(schema.SurveySummaryGeneration)

    # æ§‹é€ åŒ–å‡ºåŠ›ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰
    summary_prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """
èª¿æŸ»ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€ã“ã®å›ã®èª¿æŸ»ã‚µãƒãƒªãƒ¼ã‚’æ§‹é€ åŒ–ã•ã‚ŒãŸå½¢å¼ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ğŸ¯ èª¿æŸ»ã‚µãƒãƒªãƒ¼ç”Ÿæˆã®è¦³ç‚¹ï¼š
1. ã“ã®å›ã®èª¿æŸ»æˆ¦ç•¥ã®åŠ¹æœã¨æˆæœ
2. æ–°è¦ç™ºè¦‹ã—ãŸã‚¨ãƒªã‚¢ãƒ»åº—èˆ—ã®ç‰¹å¾´ã¨ä¾¡å€¤
3. SNSè¦³ç‚¹ã§ã®ç™ºè¦‹äº‹é …ãƒ»é­…åŠ›åº¦
4. åœ°ç†çš„ãƒ»æ¥­æ…‹çš„ãªç™ºè¦‹ãƒ‘ã‚¿ãƒ¼ãƒ³
5. å‰å›ã¾ã§ã¨ã®æ¯”è¼ƒã§ã®æ–°è¦æ€§ãƒ»ç‹¬è‡ªæ€§
ğŸ“‹ æ§‹é€ åŒ–å‡ºåŠ›è¦ä»¶ï¼š
- key_discoveries: ã“ã®å›ã®ä¸»è¦ãªç™ºè¦‹äº‹é …ï¼ˆ3-5å€‹ã®å…·ä½“çš„ã§æ´å¯Ÿã«å¯Œã‚“ã åˆ†æï¼‰
- geographical_coverage: ã“ã®å›ã§ã‚«ãƒãƒ¼ã—ãŸåœ°ç†çš„ç¯„å›²ã®èª¬æ˜
- å…·ä½“çš„ã§SNSç‰¹åŒ–è¦³ç‚¹ã‚’é‡è¦–ã—ãŸå†…å®¹
- å˜ç´”ãªæ•°å€¤ç¾…åˆ—ã‚„ä¸€èˆ¬çš„è¡¨ç¾ã‚’é¿ã‘ã‚‹
            """,
            ),
            (
                "user",
                f"""
ã€èª¿æŸ»æƒ…å ±ã€‘
é§…å: {state["station_name"]}
èª¿æŸ»å›æ•°: ç¬¬{state["survey_iteration"] + 1}å›
èª¿æŸ»æˆ¦ç•¥: {search_params["search_query"]}
é™¤å¤–æ¡ä»¶: {search_params.get("exclusion_criteria", "ãªã—")}

ã€ä»Šå›ã®æˆæœã€‘
```json
{search_result}
```

ã€æ—¢å­˜èª¿æŸ»å±¥æ­´ã€‘
```json
{survey_history}
```

ä¸Šè¨˜ã®æƒ…å ±ã‚’åˆ†æã—ã€ã“ã®å›ã®èª¿æŸ»ã§å¾—ã‚‰ã‚ŒãŸé‡è¦ãªç™ºè¦‹äº‹é …ã¨åœ°ç†çš„ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚
ä¸Šè¨˜ã®èª¿æŸ»æƒ…å ±ã‚’åˆ†æã—ã€SNSè¦³ç‚¹ã§ã®é­…åŠ›ã‚„å‰å›èª¿æŸ»ã¨ã®æ¯”è¼ƒã§ã®æ–°è¦æ€§ã«æ³¨ç›®ã—ã¦ã€
key_discoveriesã¨geographical_coverageã‚’æ§‹é€ åŒ–ã•ã‚ŒãŸå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
            """,
            ),
        ]
    )

    # æ§‹é€ åŒ–LLMãƒã‚§ãƒ¼ãƒ³ã‚’å®Ÿè¡Œ
    chain = summary_prompt | structured_llm
    analysis_result: schema.SurveySummaryGeneration = chain.invoke({})

    print("  ğŸ“ èª¿æŸ»ã‚µãƒãƒªãƒ¼ç”Ÿæˆå®Œäº†: ")
    print(f"    - æ–°è¦ç™ºè¦‹åº—èˆ—æ•°: {analysis_result.new_restaurants_count}")
    print(f"    - æ–°è¦ç™ºè¦‹ã‚¨ãƒªã‚¢: {analysis_result.new_areas_found}")
    print(f"    - ä¸»è¦ãªç™ºè¦‹äº‹é …: {analysis_result.key_discoveries}")
    print(f"    - åœ°ç†çš„ã‚«ãƒãƒ¬ãƒƒã‚¸: {analysis_result.geographical_coverage.strip()}")

    return schema.SurveySummary(
        iteration_number=state["survey_iteration"] + 1,
        search_strategy=search_params["search_query"],
        new_restaurants_count=analysis_result.new_restaurants_count,
        new_areas_found=analysis_result.new_areas_found,
        key_discoveries=analysis_result.key_discoveries,
        geographical_coverage=analysis_result.geographical_coverage.strip(),
    )


def _get_search_params(state: schema.RestaurantSurveyState) -> Dict[str, Any]:
    """æ¬¡å›èª¿æŸ»ã®æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆè£œåŠ©é–¢æ•°ãƒ»ã‚¨ãƒªã‚¢ä¸­å¿ƒï¼‰"""
    # åˆå›èª¿æŸ»ã®å ´åˆã¯ã‚¨ãƒªã‚¢åŸºæœ¬èª¿æŸ»
    if state["survey_iteration"] == 0:
        search_query = f"{state['station_name']}å‘¨è¾ºã®é£²é£Ÿåº—ãŒé›†ã¾ã‚‹ã‚¨ãƒªã‚¢ãƒ»å•†åº—è¡—ãƒ»ã‚°ãƒ«ãƒ¡ã‚¹ãƒãƒƒãƒˆã‚’èª¿æŸ»ã€‚SNSæ˜ ãˆã™ã‚‹ã‚¨ãƒªã‚¢ã‚’å„ªå…ˆã—ã€å„ã‚¨ãƒªã‚¢å†…ã®ä»£è¡¨åº—èˆ—æƒ…å ±ã‚‚å«ã‚ã¦åé›†"
        exclusion_criteria = ""
        focus_area = f"{state['station_name']}é§…å‘¨è¾ºå…¨èˆ¬"
    else:
        # 2å›ç›®ä»¥é™ã¯æˆ¦ç•¥çš„èª¿æŸ»
        search_query = state["next_plan"].search_query
        exclusion_criteria = state["next_plan"].exclusion_criteria
        focus_area = state["next_plan"].focus_area

    print(f"  ğŸ“‹ èª¿æŸ»ã‚¯ã‚¨ãƒª: {search_query}")
    print(f"  ğŸ“ é‡ç‚¹ã‚¨ãƒªã‚¢: {focus_area}")
    print(f"   é™¤å¤–æ¡ä»¶: {exclusion_criteria or 'ãªã—'}")
    return {
        "station_name": state["station_name"],
        "search_query": search_query,
        "exclusion_criteria": exclusion_criteria,
        "focus_area": focus_area,
    }


# Node 2: çµæœåˆ†æï¼†æ¬¡å›æˆ¦ç•¥ç«‹æ¡ˆãƒãƒ¼ãƒ‰ï¼ˆç´¯ç©èª¿æŸ»å±¥æ­´åˆ†ææ©Ÿèƒ½è¿½åŠ ï¼‰
def analysis_and_planning_node(state: schema.RestaurantSurveyState) -> schema.RestaurantSurveyState:
    """å‰å›ã¾ã§ã®èª¿æŸ»çµæœã‚’åˆ†æã—ã€æ¬¡å›èª¿æŸ»æˆ¦ç•¥ã‚’ç«‹æ¡ˆï¼ˆç´¯ç©å±¥æ­´ã‚’è€ƒæ…®ï¼‰"""
    print("ğŸ§  åˆ†æï¼†æˆ¦ç•¥ç«‹æ¡ˆãƒãƒ¼ãƒ‰é–‹å§‹ï¼ˆç´¯ç©èª¿æŸ»å±¥æ­´åˆ†æï¼‰")

    # æ§‹é€ åŒ–å‡ºåŠ›ã‚’ä½¿ç”¨ã™ã‚‹LLM
    analysis_llm = ChatOpenAI(model="gpt-5.1", temperature=0)
    structured_analysis_llm = analysis_llm.with_structured_output(schema.AnalysisNodeResponse)

    # ç¾åœ¨ã®èª¿æŸ»çµæœã‚’ã‚µãƒãƒªãƒ¼
    survey_history_summary = []
    for i_survey_history in state["survey_history"]:
        i_survey_history_dump = i_survey_history.model_dump()

        i_mnew_areas_found_summary = "\n".join(
            ["- " + i_new_area_found["area_name"] for i_new_area_found in i_survey_history_dump["new_areas_found"]]
        )
        i_survey_summary = f"""
## èª¿æŸ»å›æ•°: ç¬¬{i_survey_history_dump["iteration_number"]}å›
    ã€æ¤œç´¢ã‚¯ã‚¨ãƒªã€‘
    {i_survey_history_dump["search_strategy"]}

    ã€æ¤œç´¢çµæœã§å–å¾—ã§ããŸã‚¨ãƒªã‚¢ã€‘
    {i_mnew_areas_found_summary}

    ã€æ¤œç´¢çµæœã®åœ°ç†çš„ç¯„å›²ã€‘
    {i_survey_history_dump["geographical_coverage"]}

        """
        survey_history_summary.append(i_survey_summary)

    # èª¿æŸ»å±¥æ­´ã®è¦ç´„ç”Ÿæˆ
    survey_history_summary = "\n".join(survey_history_summary)

    analysis_prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """
ã‚ãªãŸã¯é£²é£Ÿåº—èª¿æŸ»ã®æˆ¦ç•¥ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
ç´¯ç©çš„ãªèª¿æŸ»å±¥æ­´ã‚’è©³ç´°ã«åˆ†æã—ã€åŒ…æ‹¬çš„ãªèª¿æŸ»ç¶™ç¶šåˆ¤å®šã¨æ¬¡å›æˆ¦ç•¥ã‚’æ±ºå®šã—ã¦ãã ã•ã„ã€‚

ç´¯ç©èª¿æŸ»åˆ†æè¦³ç‚¹ï¼š
1. åœ°ç†çš„ã‚«ãƒãƒ¬ãƒƒã‚¸ï¼ˆæ–¹è§’ãƒ»è·é›¢ç¯„å›²ã®ç¶²ç¾…æ€§ï¼‰
2. å¾’æ­©æ™‚é–“å¸¯ã®åã‚Šåˆ†æ
3. æ¥­æ…‹ã‚«ãƒ†ã‚´ãƒªã®ç¶²ç¾…æ€§ 
4. ä¾¡æ ¼å¸¯ãƒ»å®¢å±¤ã®å¤šæ§˜æ€§
5. SNSã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨ã—ã¦ã®é­…åŠ›åº¦
6. å„å›ã®èª¿æŸ»æˆ¦ç•¥ã®åŠ¹æœåˆ†æ
7. æœªèª¿æŸ»é ˜åŸŸã®ç‰¹å®š

ç¶™ç¶šåˆ¤å®šåŸºæº–ï¼š
- æ–°è¦æƒ…å ±ç™ºè¦‹ã®å¯èƒ½æ€§ï¼ˆåœ°ç†çš„ãƒ»æ¥­æ…‹çš„ã‚®ãƒ£ãƒƒãƒ—ï¼‰
- èª¿æŸ»å“è³ªã®å‘ä¸Šä½™åœ°
- SNSã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨ã—ã¦ã®å……å®Ÿåº¦
- æœ€å¤§å›æ•°ã¨ã®é–¢ä¿‚

æ¬¡å›æˆ¦ç•¥ç«‹æ¡ˆï¼š
- ã“ã‚Œã¾ã§ã®èª¿æŸ»å±¥æ­´ã§è¦‹è½ã¨ã—ãŸé ˜åŸŸ
- æˆ¦ç•¥çš„ã«é‡è¦ãªæœªèª¿æŸ»ã‚¨ãƒªã‚¢
- SNSè¦³ç‚¹ã§ä¸è¶³ã—ã¦ã„ã‚‹è¦ç´ 
- é™¤å¤–ã™ã¹ãæ—¢èª¿æŸ»å†…å®¹ã®è©³ç´°
- èª¿æŸ»åŠ¹ç‡ã‚’é«˜ã‚ã‚‹å…·ä½“çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ

çµæœã‚’ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ï¼š
1. ã€ç¶™ç¶šåˆ¤å®šã€‘Yes/No + ç†ç”±
2. ã€ç´¯ç©èª¿æŸ»ã®è©•ä¾¡ã€‘è‰¯å¥½/æ™®é€š/è¦æ”¹å–„ + æ ¹æ‹ 
3. ã€æœªèª¿æŸ»ã‚®ãƒ£ãƒƒãƒ—åˆ†æã€‘å…·ä½“çš„ãªä¸è¶³é ˜åŸŸ
4. ã€æ¬¡å›æˆ¦ç•¥ã€‘ç¶™ç¶šã®å ´åˆã®å…·ä½“çš„èª¿æŸ»æ–¹é‡
            """,
            ),
            (
                "user",
                f"""
é§…å: {state["station_name"]}
æœ€å¤§èª¿æŸ»å›æ•°: {state["max_iterations"]}

{survey_history_summary}

ä¸Šè¨˜ã®ç´¯ç©èª¿æŸ»çµæœã‚’å¤šè§’çš„ã«åˆ†æã—ã€ä»¥ä¸‹ã‚’è©³ç´°ã«åˆ¤å®šã—ã¦ãã ã•ã„ï¼š

1. èª¿æŸ»ç¶™ç¶šã®å¿…è¦æ€§ã¨æ ¹æ‹ 
2. ã“ã‚Œã¾ã§ã®èª¿æŸ»å±¥æ­´ã§ã®æˆ¦ç•¥åŠ¹æœåˆ†æ
3. æœªèª¿æŸ»é ˜åŸŸã®å…·ä½“çš„ç‰¹å®š
4. SNSã‚³ãƒ³ãƒ†ãƒ³ãƒ„è¦³ç‚¹ã§ã®å……å®Ÿåº¦è©•ä¾¡
5. æ¬¡å›èª¿æŸ»æˆ¦ç•¥ï¼ˆç¶™ç¶šã®å ´åˆï¼‰

ç‰¹ã«ç´¯ç©çš„ãªè¦–ç‚¹ã§ã€ã“ã‚Œã¾ã§ã®èª¿æŸ»ã§å–ã‚Šã“ã¼ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹é ˜åŸŸã‚’é‡è¦–ã—ã¦ãã ã•ã„ã€‚
            """,
            ),
        ]
    )

    # æ§‹é€ åŒ–åˆ†æã®å®Ÿè¡Œ
    chain = analysis_prompt | structured_analysis_llm
    analysis_result: schema.AnalysisNodeResponse = chain.invoke({})

    print("  ğŸ§¾ åˆ†æï¼†æˆ¦ç•¥ç«‹æ¡ˆå®Œäº†: ")
    print(f"    - èª¿æŸ»ç¶™ç¶šåˆ¤å®š: {'ç¶™ç¶š' if analysis_result.continue_survey else 'çµ‚äº†'}")
    print(f"    - ç¶™ç¶šãƒ»çµ‚äº†ç†ç”±: {analysis_result.continuation_reason[:100]}...")
    print(f"    - ç´¯ç©èª¿æŸ»è©•ä¾¡: {analysis_result.survey_evaluation}")
    print(f"    - æœªèª¿æŸ»ã‚®ãƒ£ãƒƒãƒ—: {analysis_result.coverage_gaps}")
    print(f"    - æ¬¡å›èª¿æŸ»æ–¹é‡: {analysis_result.next_strategy.strip()[:100]}...")

    # æ§‹é€ åŒ–å‡ºåŠ›ã‹ã‚‰ç¶™ç¶šåˆ¤å®šã‚’å–å¾—
    should_continue = analysis_result.continue_survey and state["survey_iteration"] < state["max_iterations"]

    result = {}
    if should_continue:
        result["next_plan"] = _generate_next_plan_with_llm(state, analysis_result)
    else:
        result["completion_reason"] = analysis_result.continuation_reason

    result["current_process"] = "analysis_and_planning_node"
    result["should_continue"] = should_continue
    result["current_analysis"] = analysis_result

    return result


def _generate_next_plan_with_llm(
    state: schema.RestaurantSurveyState, analysis_result: schema.AnalysisNodeResponse
) -> schema.NextSurveyPlan:
    """LLMã‚’ä½¿ç”¨ã—ã¦NextSurveyPlanã‚’ç”Ÿæˆã™ã‚‹ï¼ˆç´¯ç©èª¿æŸ»ã‚’è€ƒæ…®ï¼‰"""

    analysis_detail = (
        json.dumps(analysis_result.model_dump(), indent=2, ensure_ascii=False).replace("{", "{{").replace("}", "}}")
    )

    # æ§‹é€ åŒ–å‡ºåŠ›ã‚’ä½¿ç”¨ã™ã‚‹LLM
    plan_llm = ChatOpenAI(model="gpt-5-mini", temperature=0)
    structured_plan_llm = plan_llm.with_structured_output(schema.NextSurveyPlan)

    plan_prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """
ã‚ãªãŸã¯é£²é£Ÿåº—èª¿æŸ»ã®æˆ¦ç•¥ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã§ã™ã€‚
ç´¯ç©çš„ãªèª¿æŸ»å±¥æ­´ã¨æœ€æ–°ã®åˆ†æçµæœã‚’è¸ã¾ãˆã€æ¬¡å›èª¿æŸ»ã®å…·ä½“çš„ãªæˆ¦ç•¥è¨ˆç”»ã‚’ç«‹æ¡ˆã—ã¦ãã ã•ã„ã€‚
ç´¯ç©èª¿æŸ»è€ƒæ…®ãƒã‚¤ãƒ³ãƒˆï¼š
1. ã“ã‚Œã¾ã§ã®èª¿æŸ»ã§è¦‹è½ã¨ã—ãŸå¯èƒ½æ€§ã®ã‚ã‚‹é ˜åŸŸ
2. æˆ¦ç•¥çš„ã«é‡è¦ãªæœªèª¿æŸ»ã‚¨ãƒªã‚¢
3. SNSè¦³ç‚¹ã§ä¸è¶³ã—ã¦ã„ã‚‹è¦ç´ 
4. é™¤å¤–ã™ã¹ãæ—¢èª¿æŸ»å†…å®¹ã®è©³ç´°
5. èª¿æŸ»åŠ¹ç‡ã‚’é«˜ã‚ã‚‹å…·ä½“çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ

                """,
            ),
            (
                "user",
                f"""
é§…å: {state["station_name"]}
æœ€å¤§èª¿æŸ»å›æ•°: {state["max_iterations"]}

æœ€æ–°ã®åˆ†æçµæœ:
{analysis_detail}

ä¸Šè¨˜ã‚’è¸ã¾ãˆã€æ¬¡å›èª¿æŸ»ã®å…·ä½“çš„ãªæˆ¦ç•¥è¨ˆç”»ã‚’è©³ç´°ã«ç«‹æ¡ˆã—ã¦ãã ã•ã„ã€‚
`search_query`ã¨`exclusion_criteria`ã¯æ¬¡å›ã®èª¿æŸ»ã§ChatGPTã«æŒ‡ç¤ºã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä¸€éƒ¨ã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚

ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ä»¥ä¸‹ã®å½¢å¼ã§ã™ã€‚
```prompt
é§…å: station_name
èª¿æŸ»å†…å®¹: search_query
é™¤å¤–æ¡ä»¶: exclusion_criteria

ä¸Šè¨˜ã®æ¡ä»¶ã§SNSå‘ã‘é£²é£Ÿåº—ã‚¨ãƒªã‚¢èª¿æŸ»ã‚’å®Ÿè¡Œã—ã€**ã‚¨ãƒªã‚¢å˜ä½ã§ã¾ã¨ã‚ãŸ**æ§‹é€ åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã§è¿”ã—ã¦ãã ã•ã„ã€‚
ç‰¹ã«ä»¥ä¸‹ã‚’é‡è¦–ï¼š
- ã‚¨ãƒªã‚¢ã”ã¨ã®é£²é£Ÿåº—é›†ç©çŠ¶æ³
- ã‚¨ãƒªã‚¢å…¨ä½“ã®ã‚¤ãƒ³ã‚¹ã‚¿æ˜ ãˆã™ã‚‹ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è¦ç´ 
- ã‚¨ãƒªã‚¢ã®çµ±ä¸€æ„Ÿãƒ»ãƒ†ãƒ¼ãƒæ€§ãƒ»è©±é¡Œæ€§
- å„ã‚¨ãƒªã‚¢å†…ã®ä»£è¡¨åº—èˆ—æƒ…å ±
- ãƒ‡ãƒ¼ã‚¿ã®ä¿¡é ¼æ€§ã¨æ­£ç¢ºæ€§
```

`search_query`,`exclusion_criteria`ãŒpromptå†…ã§è‡ªç„¶ã«ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«200æ–‡å­—ä»¥å†…ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
                """,
            ),
        ]
    )

    # æ§‹é€ åŒ–ãƒ—ãƒ©ãƒ³ç”Ÿæˆã®å®Ÿè¡Œ
    chain = plan_prompt | structured_plan_llm
    next_plan: schema.NextSurveyPlan = chain.invoke({})

    print("  ğŸ—ºï¸ æ¬¡å›èª¿æŸ»è¨ˆç”»ç”Ÿæˆå®Œäº†: ")
    print(f"    - é‡ç‚¹ã‚¨ãƒªã‚¢: {next_plan.focus_area}")
    print(f"    - é‡ç‚¹æ¥­æ…‹: {next_plan.target_categories}")
    print(f"    - å¾’æ­©æ™‚é–“ç¯„å›²: {next_plan.walking_time_range}")
    print(f"    - SNSé‡è¦–ãƒã‚¤ãƒ³ãƒˆ: {next_plan.sns_focus_points}")
    print(f"    - é™¤å¤–æ¡ä»¶: {next_plan.exclusion_criteria}")

    return next_plan


# é©å¿œçš„èª¿æŸ»ã®æ¡ä»¶åˆ†å²é–¢æ•°
def should_continue_adaptive_survey(state: schema.RestaurantSurveyState) -> str:
    """èª¿æŸ»ç¶™ç¶šã®åˆ¤å®š"""

    # æœ€å¤§å›æ•°è¶…éã®å ´åˆã¯çµ‚äº†
    if state["survey_iteration"] >= state["max_iterations"]:
        return END

    # åˆå›ã¯`restaurant_survey_node`
    if "current_process" not in state or not state["current_process"]:
        return "restaurant_survey_node"

    # ç¾åœ¨ã®å‡¦ç†ãŒã‚ã‚‹å ´åˆã¯ã€åå¯¾å´ã®å‡¦ç†ã‚’å®Ÿè¡Œ
    if state["current_process"] == "restaurant_survey_node":
        return "analysis_and_planning_node"

    elif state["current_process"] == "analysis_and_planning_node":
        # ç¶™ç¶šãƒ•ãƒ©ã‚°ãŒ False ã®å ´åˆã¯çµ‚äº†
        if not state["should_continue"]:
            return END
        return "restaurant_survey_node"

    else:
        raise Exception(f"æƒ³å®šã•ã‚Œãªã„ãƒ•ãƒ­ãƒ¼ã§ã™: {state['current_process']}")
