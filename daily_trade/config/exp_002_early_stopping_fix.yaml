# 実験002: 早期停止設定の修正
# 目的: 適切な学習回数の確保と汎化性能向上

dataset:
  input_file: "./data/ohlcv/latest_dataset.parquet"
  output_prefix: "exp_002"

model:
  type: "LightGBM"
  params:
    objective: "binary"
    metric: "auc"
    boosting_type: "gbdt"
    num_leaves: 31
    learning_rate: 0.05 # より保守的な学習率
    feature_fraction: 0.9
    bagging_fraction: 0.8
    bagging_freq: 5
    verbose: -1
    random_state: 42
    early_stopping_rounds: 50 # 早期停止を緩和（10→50）
    num_boost_round: 500 # 最大回数を増加（100→500）

validation:
  method: "TimeSeriesSplit"
  n_splits: 5
  test_size: 0.2

output:
  model_file: "./models/exp_002_model.pkl"
  report_file: "./models/exp_002_model_report.json"
# 実験仮説:
# - early_stopping_roundsを50に増加することで適切な学習回数を確保
# - learning_rateを0.05に下げることで過学習を抑制
# - CV結果と最終結果の乖離を減少させる
