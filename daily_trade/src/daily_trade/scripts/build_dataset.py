#!/usr/bin/env python3
"""build_dataset.py - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰CLI.

ãƒ‡ãƒ¼ã‚¿å–å¾—ã‹ã‚‰ç‰¹å¾´é‡ç”Ÿæˆã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä½œæˆã¾ã§ã®å…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã—ã€
æ©Ÿæ¢°å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚

Usage:
    python -m daily_trade.scripts.build_dataset --config config.yaml
    python -m daily_trade.scripts.build_dataset --symbols AAPL MSFT --start 2020-01-01 --end 2025-01-01
"""

import argparse
from datetime import datetime
from pathlib import Path
import sys
from typing import Optional

import yaml
import yfinance as yf

from daily_trade.data.feature_builder import FeatureBuilder, FeatureConfig
from daily_trade.data.loader import DataLoader, LoadConfig
from daily_trade.data.preprocessor import PreprocessConfig, Preprocessor
from daily_trade.target_generator import TargetConfig, TargetGenerator
from daily_trade.utils.logger import AppLogger


def load_symbols_config(config_path: Optional[str] = None) -> dict:
    """éŠ˜æŸ„è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿.

    Args:
        config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆæŒ‡å®šãªã—ã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ï¼‰

    Returns:
        éŠ˜æŸ„è¨­å®šè¾æ›¸
    """
    if config_path is None:
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹
        project_root = Path(__file__).parent.parent.parent.parent
        config_path = project_root / "config" / "symbols.yaml"

    config_file = Path(config_path)
    if not config_file.exists():
        raise FileNotFoundError(f"éŠ˜æŸ„è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_path}")

    with config_file.open(encoding="utf-8") as f:
        return yaml.safe_load(f)


def get_symbols_from_categories(categories: list[str], remove_duplicates: bool = True) -> list[str]:
    """è¤‡æ•°ã®ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰éŠ˜æŸ„ãƒªã‚¹ãƒˆã‚’å–å¾—ãƒ»çµ±åˆ.

    Args:
        categories: éŠ˜æŸ„ã‚«ãƒ†ã‚´ãƒªã®ãƒªã‚¹ãƒˆ
        remove_duplicates: é‡è¤‡éŠ˜æŸ„ã‚’é™¤å»ã™ã‚‹ã‹ã©ã†ã‹

    Returns:
        çµ±åˆã•ã‚ŒãŸéŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
    """
    logger = AppLogger()
    all_symbols = []
    category_details = {}

    # å„ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰éŠ˜æŸ„ã‚’å–å¾—
    for category in categories:
        symbols = get_predefined_symbols(category)
        all_symbols.extend(symbols)
        category_details[category] = len(symbols)
        logger.info(f"ã‚«ãƒ†ã‚´ãƒª '{category}' ã‹ã‚‰ {len(symbols)} éŠ˜æŸ„ã‚’å–å¾—")

    # é‡è¤‡é™¤å»
    if remove_duplicates:
        unique_symbols = list(dict.fromkeys(all_symbols))  # é †åºã‚’ä¿æŒã—ã¤ã¤é‡è¤‡é™¤å»
        duplicate_count = len(all_symbols) - len(unique_symbols)
        if duplicate_count > 0:
            logger.info(f"é‡è¤‡éŠ˜æŸ„ {duplicate_count} å€‹ã‚’é™¤å»")
        all_symbols = unique_symbols

    logger.info(f"æœ€çµ‚éŠ˜æŸ„æ•°: {len(all_symbols)}")

    # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®è©³ç´°ã‚’ãƒ­ã‚°å‡ºåŠ›
    for category, count in category_details.items():
        logger.info(f"  {category}: {count}éŠ˜æŸ„")

    return all_symbols


def get_predefined_symbols(category: str = "popular", include_details: bool = False) -> list[str] | dict:
    """äº‹å‰å®šç¾©ã•ã‚ŒãŸéŠ˜æŸ„ãƒªã‚¹ãƒˆã‚’å–å¾—.

    Args:
        category: éŠ˜æŸ„ã‚«ãƒ†ã‚´ãƒª
            - "popular": äººæ°—ç±³å›½æ ª (FAANG + ä¸»è¦éŠ˜æŸ„)
            - "dow30": ãƒ€ã‚¦å¹³å‡æ§‹æˆéŠ˜æŸ„ (ä»£è¡¨çš„ãª30éŠ˜æŸ„)
            - "sp500_tech": S&P500ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã‚»ã‚¯ã‚¿ãƒ¼ä¸»è¦éŠ˜æŸ„
            - "etf": ä¸»è¦ETF
            - "jp_major": æ—¥æœ¬ä¸»è¦éŠ˜æŸ„
        include_details: ä¼æ¥­åã¨ã‚»ã‚¯ã‚¿ãƒ¼æƒ…å ±ã‚‚å«ã‚ã¦è¿”ã™ã‹ã©ã†ã‹

    Returns:
        éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ ã¾ãŸã¯ è©³ç´°æƒ…å ±ä»˜ãè¾æ›¸
    """
    try:
        symbols_config = load_symbols_config()
        category_data = symbols_config["symbol_categories"].get(category)

        if not category_data:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: äººæ°—éŠ˜æŸ„ã‚’è¿”ã™
            category_data = symbols_config["symbol_categories"]["popular"]

        if include_details:
            return {"description": category_data["description"], "symbols": category_data["symbols"]}
        return [item["symbol"] for item in category_data["symbols"]]

    except Exception as e:
        logger = AppLogger()
        logger.error(f"éŠ˜æŸ„è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸäººæ°—éŠ˜æŸ„
        fallback_symbols = ["AAPL", "MSFT", "GOOGL", "AMZN", "NVDA", "META", "TSLA", "NFLX", "V", "JPM"]

        if include_details:
            return {
                "description": "ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ä¸»è¦ç±³å›½æ ª",
                "symbols": [{"symbol": s, "name": "N/A", "sector": "N/A"} for s in fallback_symbols],
            }
        return fallback_symbols


def fetch_symbols_from_yfinance(tickers: list[str], validate: bool = True) -> list[str]:
    """yfinanceã‹ã‚‰éŠ˜æŸ„æƒ…å ±ã‚’å–å¾—ã—ã¦æœ‰åŠ¹æ€§ã‚’æ¤œè¨¼.

    Args:
        tickers: æ¤œè¨¼å¯¾è±¡ã®éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
        validate: éŠ˜æŸ„ã®æœ‰åŠ¹æ€§ã‚’æ¤œè¨¼ã™ã‚‹ã‹ã©ã†ã‹

    Returns:
        æœ‰åŠ¹ãªéŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
    """
    if not validate:
        return tickers

    logger = AppLogger()
    logger.info(f"éŠ˜æŸ„æœ‰åŠ¹æ€§æ¤œè¨¼é–‹å§‹: {len(tickers)}éŠ˜æŸ„")

    valid_symbols = []

    for ticker in tickers:
        try:
            # yfinanceã§éŠ˜æŸ„æƒ…å ±ã‚’å–å¾—
            stock = yf.Ticker(ticker)
            info = stock.info

            # åŸºæœ¬æƒ…å ±ãŒå–å¾—ã§ãã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if info and "symbol" in info:
                valid_symbols.append(ticker)
                logger.info(f"âœ… {ticker}: {info.get('shortName', 'N/A')}")
            else:
                logger.warning(f"âŒ {ticker}: éŠ˜æŸ„æƒ…å ±å–å¾—å¤±æ•—")

        except Exception as e:
            logger.warning(f"âŒ {ticker}: ã‚¨ãƒ©ãƒ¼ - {str(e)[:50]}")
            continue

    logger.info(f"æœ‰åŠ¹éŠ˜æŸ„æ•°: {len(valid_symbols)}/{len(tickers)}")
    return valid_symbols


def list_available_symbol_categories() -> None:
    """åˆ©ç”¨å¯èƒ½ãªéŠ˜æŸ„ã‚«ãƒ†ã‚´ãƒªã‚’è¡¨ç¤º."""
    try:
        symbols_config = load_symbols_config()
        categories = symbols_config["symbol_categories"]

        print("ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªéŠ˜æŸ„ã‚«ãƒ†ã‚´ãƒª:")
        for key, category_data in categories.items():
            description = category_data["description"]
            symbols = [item["symbol"] for item in category_data["symbols"]]
            count = len(symbols)

            print(f"  {key:12}: {description} - {count}éŠ˜æŸ„")

            # æœ€åˆã®10éŠ˜æŸ„ã‚’è¡¨ç¤ºï¼ˆä¼æ¥­åä»˜ãï¼‰
            display_symbols = []
            for item in category_data["symbols"][:10]:
                symbol = item["symbol"]
                name = item["name"]
                # ä¼æ¥­åãŒé•·ã„å ´åˆã¯çŸ­ç¸®
                if len(name) > 25:
                    short_name = name[:22] + "..."
                else:
                    short_name = name
                display_symbols.append(f"{symbol}({short_name})")

            display_text = " ".join(display_symbols)
            if len(symbols) > 10:
                display_text += " ..."

            print(f"               {display_text}")
            print()

    except Exception as e:
        print(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        print("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚«ãƒ†ã‚´ãƒªã‚’è¡¨ç¤ºã—ã¾ã™...")

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¡¨ç¤º
        fallback_categories = {
            "popular": "äººæ°—ç±³å›½æ ª (FAANG + ä¸»è¦éŠ˜æŸ„) - 10éŠ˜æŸ„",
            "dow30": "ãƒ€ã‚¦å¹³å‡æ§‹æˆéŠ˜æŸ„ - 30éŠ˜æŸ„",
            "sp500_tech": "S&P500ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã‚»ã‚¯ã‚¿ãƒ¼ä¸»è¦éŠ˜æŸ„ - 20éŠ˜æŸ„",
            "etf": "ä¸»è¦ETF - 15éŠ˜æŸ„",
            "jp_major": "æ—¥æœ¬ä¸»è¦éŠ˜æŸ„ - 15éŠ˜æŸ„",
        }

        print("ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªéŠ˜æŸ„ã‚«ãƒ†ã‚´ãƒª:")
        for key, description in fallback_categories.items():
            symbols = get_predefined_symbols(key)
            print(f"  {key:12}: {description}")
            print(f"               {' '.join(symbols[:10])}" + (" ..." if len(symbols) > 10 else ""))
            print()


def load_config_from_yaml(config_path: str) -> dict:
    """YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿."""
    config_file = Path(config_path)
    with config_file.open(encoding="utf-8") as f:
        return yaml.safe_load(f)


def create_output_path(base_dir: str = "./data", filename: str = "daily_ohlcv_features.parquet") -> Path:
    """å‡ºåŠ›ãƒ‘ã‚¹ã‚’ä½œæˆ."""
    output_dir = Path(base_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    return output_dir / filename


def _log_dataset_stats(logger: AppLogger, final_data) -> None:
    """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±è¨ˆã‚’ãƒ­ã‚°å‡ºåŠ›."""
    logger.info("6. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±è¨ˆ:")
    logger.info(f"  ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(final_data):,}")
    logger.info(f"  éŠ˜æŸ„æ•°: {final_data['symbol'].nunique()}")
    logger.info(f"  æœŸé–“: {final_data['timestamp'].min()} - {final_data['timestamp'].max()}")
    feature_cols = [col for col in final_data.columns if col not in ["symbol", "timestamp", "next_ret", "y_up"]]
    logger.info(f"  ç‰¹å¾´é‡æ•°: {len(feature_cols)}")
    logger.info(f"  ä¸Šæ˜‡ç‡: {final_data['y_up'].mean():.1%}")


def _log_symbol_stats(logger: AppLogger, final_data) -> None:
    """éŠ˜æŸ„åˆ¥çµ±è¨ˆã‚’ãƒ­ã‚°å‡ºåŠ›."""
    symbol_stats = final_data.groupby("symbol").agg({"y_up": ["count", "mean"], "next_ret": ["mean", "std"]}).round(3)
    logger.info("7. éŠ˜æŸ„åˆ¥çµ±è¨ˆ:")
    for symbol in symbol_stats.index:
        count = symbol_stats.loc[symbol, ("y_up", "count")]
        up_rate = symbol_stats.loc[symbol, ("y_up", "mean")]
        mean_ret = symbol_stats.loc[symbol, ("next_ret", "mean")]
        std_ret = symbol_stats.loc[symbol, ("next_ret", "std")]
        logger.info(f"  {symbol}: {count}æ—¥, ä¸Šæ˜‡ç‡={up_rate:.1%}, ãƒªã‚¿ãƒ¼ãƒ³={mean_ret:.3f}Â±{std_ret:.3f}")


def build_dataset(
    symbols: list[str],
    start_date: str,
    end_date: str,
    interval: str = "1d",
    margin_pct: float = 0.01,
    output_path: Optional[str] = None,
    winsorize_pct: float = 0.01,
    min_trading_days: int = 100,
) -> str:
    """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰ãƒ¡ã‚¤ãƒ³å‡¦ç†.

    Args:
        symbols: éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
        start_date: é–‹å§‹æ—¥ (YYYY-MM-DD)
        end_date: çµ‚äº†æ—¥ (YYYY-MM-DD)
        interval: ãƒ‡ãƒ¼ã‚¿é–“éš” (1d, 1wk, 1mo)
        margin_pct: ä¸Šæ˜‡åˆ¤å®šãƒãƒ¼ã‚¸ãƒ³ (0.01 = 1%)
        output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        winsorize_pct: Winsorizeå‡¦ç†ã®é–¾å€¤
        min_trading_days: æœ€å°å–å¼•æ—¥æ•°

    Returns:
        å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    """
    logger = AppLogger()
    logger.info("=== ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰é–‹å§‹ ===")
    logger.info(f"éŠ˜æŸ„: {symbols}")
    logger.info(f"æœŸé–“: {start_date} - {end_date}")
    logger.info(f"ãƒãƒ¼ã‚¸ãƒ³: {margin_pct:.1%}")

    # å‡ºåŠ›ãƒ‘ã‚¹æ±ºå®š
    if output_path is None:
        output_path = create_output_path()
    else:
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

    try:
        # 1. ãƒ‡ãƒ¼ã‚¿å–å¾—
        logger.info("1. ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹...")
        loader_config = LoadConfig(start=start_date, end=end_date, interval=interval)
        loader = DataLoader(loader_config)
        raw_data = loader.load_ohlcv(symbols)
        logger.info(f"Raw data: {raw_data.shape}")

        # 2. å‰å‡¦ç†
        logger.info("2. å‰å‡¦ç†é–‹å§‹...")
        preprocess_config = PreprocessConfig(
            winsorize_limits=(winsorize_pct, 1.0 - winsorize_pct),
            min_trading_days=min_trading_days,
        )
        preprocessor = Preprocessor(preprocess_config)
        clean_data = preprocessor.clean(raw_data)
        logger.info(f"Clean data: {clean_data.shape}")

        # 3. ç‰¹å¾´é‡ç”Ÿæˆ
        logger.info("3. ç‰¹å¾´é‡ç”Ÿæˆé–‹å§‹...")
        feature_config = FeatureConfig()
        feature_builder = FeatureBuilder(feature_config)
        feature_data, feature_columns = feature_builder.build(clean_data)
        logger.info(f"Feature data: {feature_data.shape}, columns: {len(feature_columns)}")

        # 4. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”Ÿæˆ
        logger.info("4. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”Ÿæˆé–‹å§‹...")
        target_config = TargetConfig(margin_pct=margin_pct)
        target_generator = TargetGenerator(target_config)
        final_data = target_generator.make_targets(feature_data)
        logger.info(f"Final data: {final_data.shape}")

        # 5. ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        logger.info("5. ãƒ‡ãƒ¼ã‚¿ä¿å­˜é–‹å§‹...")
        final_data.to_parquet(output_path, index=False)
        with Path.open(output_path.with_suffix(".features.txt"), "w", encoding="utf-8") as f:
            for col in feature_columns:
                f.write(f"{col}\n")
        logger.info(f"ç‰¹å¾´é‡ãƒªã‚¹ãƒˆä¿å­˜: {output_path.with_suffix('.features.txt')}")
        logger.info(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¿å­˜å®Œäº†: {output_path}")

        # 6. çµ±è¨ˆã‚µãƒãƒªãƒ¼
        _log_dataset_stats(logger, final_data)

        # 7. éŠ˜æŸ„åˆ¥çµ±è¨ˆ
        _log_symbol_stats(logger, final_data)

        logger.info("=== ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰å®Œäº† ===")
        return str(output_path)

    except Exception as e:
        logger.error(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
        raise


def main():
    """CLI ãƒ¡ã‚¤ãƒ³å‡¦ç†."""
    parser = argparse.ArgumentParser(
        description="ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰CLI",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å®Ÿè¡Œ
  python -m daily_trade.scripts.build_dataset --config config.yaml

  # CLIå¼•æ•°ã§ç›´æ¥æŒ‡å®š
  python -m daily_trade.scripts.build_dataset \\
    --symbols AAPL MSFT GOOGL \\
    --start 2020-01-01 \\
    --end 2025-01-01 \\
    --margin 0.01 \\
    --output ./data/dataset.parquet

  # äº‹å‰å®šç¾©éŠ˜æŸ„ã‚«ãƒ†ã‚´ãƒªã‚’ä½¿ç”¨
  python -m daily_trade.scripts.build_dataset \\
    --symbol-category popular \\
    --start 2020-01-01 \\
    --end 2025-01-01

  # è¤‡æ•°ã‚«ãƒ†ã‚´ãƒªã‚’çµ„ã¿åˆã‚ã›
  python -m daily_trade.scripts.build_dataset \\
    --symbol-category popular etf \\
    --start 2020-01-01 \\
    --end 2025-01-01

  # éŠ˜æŸ„ã‚«ãƒ†ã‚´ãƒªä¸€è¦§ã‚’è¡¨ç¤º
  python -m daily_trade.scripts.build_dataset --list-categories

  # éŠ˜æŸ„æ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦é«˜é€Ÿå®Ÿè¡Œ
  python -m daily_trade.scripts.build_dataset \\
    --symbols AAPL MSFT GOOGL \\
    --no-validate \\
    --start 2020-01-01 \\
    --end 2025-01-01
        """,
    )

    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
    parser.add_argument("--config", "-c", type=str, help="YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹")

    # ãƒ‡ãƒ¼ã‚¿å–å¾—è¨­å®š
    parser.add_argument(
        "--symbols",
        "-s",
        type=str,
        nargs="+",
        help="éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ (ä¾‹: AAPL MSFT GOOGL)",
    )

    parser.add_argument(
        "--symbol-category",
        type=str,
        nargs="+",
        choices=["popular", "dow30", "sp500_tech", "etf", "jp_major"],
        help="äº‹å‰å®šç¾©ã•ã‚ŒãŸéŠ˜æŸ„ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰é¸æŠ (è¤‡æ•°æŒ‡å®šå¯èƒ½ã€--list-categories ã§ä¸€è¦§è¡¨ç¤º)",
    )

    parser.add_argument(
        "--list-categories",
        action="store_true",
        help="åˆ©ç”¨å¯èƒ½ãªéŠ˜æŸ„ã‚«ãƒ†ã‚´ãƒªã‚’è¡¨ç¤ºã—ã¦çµ‚äº†",
    )

    parser.add_argument(
        "--validate-symbols",
        action="store_true",
        default=True,
        help="yfinanceã§éŠ˜æŸ„ã®æœ‰åŠ¹æ€§ã‚’æ¤œè¨¼ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: True)",
    )

    parser.add_argument(
        "--no-validate",
        action="store_true",
        help="éŠ˜æŸ„ã®æœ‰åŠ¹æ€§æ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—",
    )

    parser.add_argument("--start", type=str, help="é–‹å§‹æ—¥ (YYYY-MM-DD)")

    parser.add_argument("--end", type=str, help="çµ‚äº†æ—¥ (YYYY-MM-DD)")

    parser.add_argument(
        "--interval",
        type=str,
        default="1d",
        choices=["1d", "1wk", "1mo"],
        help="ãƒ‡ãƒ¼ã‚¿é–“éš” (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1d)",
    )

    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¨­å®š
    parser.add_argument(
        "--margin",
        type=float,
        default=0.01,
        help="ä¸Šæ˜‡åˆ¤å®šãƒãƒ¼ã‚¸ãƒ³ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.01 = 1%%)",
    )

    # å‰å‡¦ç†è¨­å®š
    parser.add_argument(
        "--winsorize",
        type=float,
        default=0.01,
        help="Winsorizeé–¾å€¤ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.01 = 1%%)",
    )

    parser.add_argument("--min-days", type=int, default=100, help="æœ€å°å–å¼•æ—¥æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 100)")

    # å‡ºåŠ›è¨­å®š
    parser.add_argument(
        "--output",
        "-o",
        type=str,
        help="å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ./data/daily_ohlcv_features.parquet)",
    )

    # ãƒ­ã‚°è¨­å®š
    parser.add_argument("--verbose", "-v", action="store_true", help="è©³ç´°ãƒ­ã‚°å‡ºåŠ›")

    args = parser.parse_args()

    try:
        # --list-categories ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®å‡¦ç†
        if args.list_categories:
            list_available_symbol_categories()
            return

        # è¨­å®šèª­ã¿è¾¼ã¿
        if args.config:
            # YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
            config = load_config_from_yaml(args.config)
            symbols = config.get("symbols", [])
            start_date = config.get("start_date")
            end_date = config.get("end_date")
            interval = config.get("interval", "1d")
            margin_pct = config.get("margin_pct", 0.01)
            output_path = config.get("output_path")
            winsorize_pct = config.get("winsorize_pct", 0.01)
            min_trading_days = config.get("min_trading_days", 100)
            validate_symbols = config.get("validate_symbols", True)
        else:
            # CLIå¼•æ•°ã‹ã‚‰èª­ã¿è¾¼ã¿
            symbols = args.symbols
            start_date = args.start
            end_date = args.end
            interval = args.interval
            margin_pct = args.margin
            output_path = args.output
            winsorize_pct = args.winsorize
            min_trading_days = args.min_days
            validate_symbols = args.validate_symbols and not args.no_validate

        # éŠ˜æŸ„ãƒªã‚¹ãƒˆã®æ±ºå®š
        if args.symbol_category:
            # äº‹å‰å®šç¾©ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰å–å¾—
            if len(args.symbol_category) == 1:
                # å˜ä¸€ã‚«ãƒ†ã‚´ãƒª
                symbols = get_predefined_symbols(args.symbol_category[0])
                print(f"ğŸ“‹ éŠ˜æŸ„ã‚«ãƒ†ã‚´ãƒª '{args.symbol_category[0]}' ã‹ã‚‰ {len(symbols)} éŠ˜æŸ„ã‚’é¸æŠ")
            else:
                # è¤‡æ•°ã‚«ãƒ†ã‚´ãƒª
                symbols = get_symbols_from_categories(args.symbol_category)
                category_list = ", ".join(args.symbol_category)
                print(f"ğŸ“‹ éŠ˜æŸ„ã‚«ãƒ†ã‚´ãƒª [{category_list}] ã‹ã‚‰ {len(symbols)} éŠ˜æŸ„ã‚’é¸æŠ")
                print(f"   (é‡è¤‡é™¤å»å¾Œã®æœ€çµ‚éŠ˜æŸ„æ•°: {len(symbols)})")
        elif not symbols:
            parser.error("éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ (--symbols) ã¾ãŸã¯éŠ˜æŸ„ã‚«ãƒ†ã‚´ãƒª (--symbol-category) ã¯å¿…é ˆã§ã™")

        # éŠ˜æŸ„ã®æœ‰åŠ¹æ€§æ¤œè¨¼
        if validate_symbols:
            symbols = fetch_symbols_from_yfinance(symbols, validate=True)
            if not symbols:
                parser.error("æœ‰åŠ¹ãªéŠ˜æŸ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

        # å¿…é ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
        if not start_date:
            parser.error("é–‹å§‹æ—¥ (--start) ã¯å¿…é ˆã§ã™")
        if not end_date:
            parser.error("çµ‚äº†æ—¥ (--end) ã¯å¿…é ˆã§ã™")

        # æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãƒã‚§ãƒƒã‚¯
        try:
            datetime.strptime(start_date, "%Y-%m-%d")
            datetime.strptime(end_date, "%Y-%m-%d")
        except ValueError as e:
            parser.error(f"æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {e}")

        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰å®Ÿè¡Œ
        output_file = build_dataset(
            symbols=symbols,
            start_date=start_date,
            end_date=end_date,
            interval=interval,
            margin_pct=margin_pct,
            output_path=output_path,
            winsorize_pct=winsorize_pct,
            min_trading_days=min_trading_days,
        )

        print(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰å®Œäº†: {output_file}")

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
